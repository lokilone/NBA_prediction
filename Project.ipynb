{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Predicting NBA results using Machine Learning methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Machine Learning, NBA prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    For practical reasons, our training and testing will be done on data from the 2018 NBA season (more recent data is very difficult to find for free). The data is taken from the following kaggle page: https://www.kaggle.com/ionaskel/nba-games-stats-from-2014-to-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Data Analysis & Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Analysis of the data\n",
    "\n",
    "    Currently, each data corresponds to the teams' performance during the match. It contains the home team's name, it's opponent's name, the date of the match and the location which are all predictable attributes. It also contains the teams' statistics during the match which aren't predictable. Finally, it contains the match's result which will be the label of our training data. \n",
    "    The raw data's structure is the following:\n",
    "    \n",
    "    Data = {'gameID', 'teamID', 'gameNumber', ...}",
    [
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "    We want to build a predictive algorithm. Therefore, the attributes of our data must be determined before the game actually happens. \n",
    "\n",
    "    We chose past season's performances not to influence the results of the present season. Indeed, in the NBA, many player transfers are made during the offseason which can drastically modify the league's profile. For example, from 2019 to 2020, the Golden State Warriors went from being one of the best teams in history to being last of the league.\n",
    "    That is why we will only consider the data from the 2018 season.\n",
    "\n",
    "    Our preprocessed data's structure will be very different to the raw data. Indeed, the statistics attributes from each team will be replaced by a mean of the said statistic over the past games played. Therefore, every attribute can be determined before the match actually happens.\n",
    "    \n",
    "    Data = {'home_TeamID', 'away_TeamID', 'homeGameNumber', 'homeTeamPoints', 'homeOpponentPoints, 'homeFieldGoals', 'homeFieldGoal%', 'home3PointsShots', 'home3Points%', 'homeFreeThrows', 'homeFreeThrows%', 'homeOffensiveRebounds', 'homeTotalRebounds', 'homeAssists', 'homeSteals', 'homeBlocks', 'homeTurnovers', 'homeTotalFouls', 'awayGameNumber', 'awayTeamPoints', 'awayOpponentPoints, 'awayFieldGoals', 'awayFieldGoal%', 'away3PointsShots', 'away3Points%', 'awayFreeThrows', 'awayFreeThrows%', 'awayOffensiveRebounds', 'awayTotalRebounds', 'awayAssists', 'awaySteals', 'awayBlocks', 'awayTurnovers', 'awayTotalFouls'}\n",
    "    Label = {'HomeOrAwayWin'}\n",
    "    \n",
    "    Remarks: \n",
    "    1) The gameID is omitted from our preprocessed data as it doesn't influence the game's final result.\n",
    "    2) The match's date is also omitted as we consider it doesn't have a direct impact on the result of the match. What will influence the result is the number of games played in the season (players get tired). This information is contained in the 'homeGameNumber' and 'awayGameNumber' attributes.\n",
    "    3) We do not yet know whether having two attributes linked to the same statistic (Field Goals/Field Goals %; 3 Points Shots/ 3 Points Shots %...) is redundant or not.\n",
    "    4) We only consider the teams' overall statistics. If results aren't completely satisfying, we may consider statistics from each player.\n",
    "    5) As we explained above, our data must be determined before the game we are trying to predict takes place. Taking the statistics from the game we are trying to predict doesn't make sense. Therefore, the statistical attributes of our data are a mean of the corresponding statistic over the previous games of the team . \n",
    "    If the game is played home, we will only consider the team's home performances and equally for a game played away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a date from its string format to a tuple (in order to get the chronological order)\n",
    "def date_to_tuple(date):\n",
    "    A = date.split(\"-\")\n",
    "    return (int(A[0]), int(A[1]), int(A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Load data from .csv file\n",
    "\n",
    "with open('nba.games.stats.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=',', quotechar = '\"')\n",
    "    \n",
    "    # Initialize list of raw data from 2017-2018 season\n",
    "    raw_data = []\n",
    "    raw_data_test = []\n",
    "    for row in reader:\n",
    "        if not row[3]=='Date':\n",
    "            if (2017,10,1) < date_to_tuple(row[3]):\n",
    "                raw_data.append(row[1:])\n",
    "                raw_data_test.append(row[1:])\n",
    "\n",
    "                \n",
    "# Transform the statistics from strings to floats\n",
    "for i in range(len(raw_data)):\n",
    "    raw_data[i][1] = float(raw_data[i][1])\n",
    "    for j in range(6,40):\n",
    "        raw_data[i][j] = float(raw_data[i][j])\n",
    "        \n",
    "# teams is the list of teams in alphabetical order\n",
    "teams = []\n",
    "for data in raw_data:\n",
    "    if data[0] not in teams:\n",
    "        teams.append(data[0])\n",
    "\n",
    "#  Change the name of the team to its index in teams\n",
    "# 'Away' takes value 0 and 'Home' takes value +1\n",
    "# Change the opponent's name to its index in teams\n",
    "# W takes value +1 and L takes value 0\n",
    "for data in raw_data:\n",
    "    data[0] = float(teams.index(data[0]))\n",
    "    if data[3] == 'Home': data[3] = 1.\n",
    "    else: data[3] = 0.\n",
    "    data[4] = float(teams.index(data[4]))\n",
    "    if data[5] == 'W': data[5] = 1.\n",
    "    else: data[5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Data Preprocessing\n",
    "\n",
    "# Finds the data correponding to the away team\n",
    "def find_away_data(data):\n",
    "    for away_data in raw_data:\n",
    "        # If the matches were held on the same day and the teams are the same, then it is the same match\n",
    "        if away_data[2] == data[2] and away_data[4] == data[0]:\n",
    "            return away_data\n",
    "\n",
    "# Computes the statistical attributes of a team with regard to the date and the home/away status of the game\n",
    "# At this point, we are only computing the isomean of the stats on every past game (no weighted mean)\n",
    "def stats(teamID, date, HomeOrAway):\n",
    "    # Take all of the games previously played by the team at HomeOrAway before the date \n",
    "    interesting_data = np.array([w[7:] for w in raw_data if teamID == w[0] and HomeOrAway == w[3] and w[2] < date ])\n",
    "    if interesting_data.shape[0] > 0:\n",
    "    #Returns in that order: teamPoints, opponentPoints, fieldGoals, fieldGoalsPour, threePoints, threePointsPour, freeThrows, freeThrowsPour, offRebounds, totRebounds, assists, steals, blocks, turnovers, totalFouls\n",
    "        return(np.mean(interesting_data[:,[0,2,4,5,6,7,8,10,11,12,13,14,15,16,17]], axis=0))\n",
    "    return(np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data=[]\n",
    "labels = []\n",
    "\n",
    "# For the labels, +1 indicates a home win, 0 indicates an away win\n",
    "\n",
    "for data in raw_data:\n",
    "    if data[3] == 1.:\n",
    "        # Computing every attribute necessary for the data\n",
    "        away_data = find_away_data(data)\n",
    "        home_teamID = data[0]\n",
    "        away_teamID = away_data[0]\n",
    "        date = data[2]\n",
    "        homeGameNumber = data[1]\n",
    "        awayGameNumber = away_data[1]\n",
    "        home_stats = stats(home_teamID, date, 1.)\n",
    "        away_stats = stats(away_teamID, date, 0.)\n",
    "        #filling labels\n",
    "        if data[5] == 1.: labels.append(1)\n",
    "        else: labels.append(0)\n",
    "        data = np.zeros(len(home_stats)+len(away_stats)+4)\n",
    "        # Creating the new data instance\n",
    "        data[0] = home_teamID\n",
    "        data[1] = away_teamID\n",
    "        data[2] = homeGameNumber\n",
    "        counter = 3\n",
    "        for i in range(len(home_stats)):\n",
    "            data[counter] = home_stats[i]\n",
    "            counter += 1\n",
    "        data[counter] = awayGameNumber\n",
    "        counter += 1\n",
    "        for i in range(len(away_stats)):\n",
    "            data[counter] = away_stats[i]\n",
    "            counter += 1\n",
    "        preprocessed_data.append(data)\n",
    "        \n",
    "# Our data matrix is of size 1230 x 34; see preprocessing text for further understanding\n",
    "preprocessed_data = np.array(preprocessed_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Applying Classical Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6009852216748769"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree (choisi un label et coupe le jeu de données en deux au mieux selon ce label et on le répète à l'infini, ça cause une surinterprétation)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.33, random_state=1)\n",
    "regressor = DecisionTreeRegressor(random_state =42)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Decision trees give a very unsatisfying result. Let's try the bagging version of decision trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5960591133004927\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (on prend plein d'arbres, pour chaque Y, on prend comme résultat la majorité)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    Results are much better with random forests.\n",
    "    We will try to optimize the hyperparameters of the random forest classifier using Grid Search Cross-Validation methods (cf. \"Hyperparameter Tuning the Random Forest in Python\", Will Koehrsen; \"Optimizing Hyperparameters in Random Forest Classification\", Reilly Meinert.)\n",
    "    Hyperparameters we consider to optimize are: the number of trees in the forest and the maximal depth.\n",
    "    We consider the largest grid of hyperparameters on which our program can run in a reasonnable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-17144d319d76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mgridSearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [2*n for n in range(75, 100)],\n",
    "    'max_depth':[3,5,7,9,10]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(), param_grid, cv=2)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", gridSearch.best_params_)\n",
    "print(\"Score: \", gridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The optimal parameters given by the above code are : {'max_depth': 9, 'n_estimators': 156} that obtain a cross-validation score of: 0.6529126213592233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5886699507389163\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "# Using the MLP classifier that trains the model by backpropagation\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.604\n",
      "Accuracy score (validation): 0.594\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.623\n",
      "Accuracy score (validation): 0.623\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.654\n",
      "Accuracy score (validation): 0.603\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.699\n",
      "Accuracy score (validation): 0.611\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.757\n",
      "Accuracy score (validation): 0.628\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.762\n",
      "Accuracy score (validation): 0.616\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.762\n",
      "Accuracy score (validation): 0.601\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6625615763546798\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    Remarks after the first training period:\n",
    "    \n",
    "    The final results are statisfying with regard to our expectations at the beginning of the project (aim of over 60% succes rate). By choosing the right learning parameters in the random forest method, we reach near 65% prediction rate over the test data. Nevertheless, these results are still very poor in comparison to the best performing algorithms in the business (reaching up to 75% success rate). \n",
    "    We will consider the following actions in order to boost our results:\n",
    "    1) We must take into account a team's dynamic. Therefore, rather than computing the mean of a statistic over an entire season , we will only consider the last few games played by the team and compute a weighted mean over these games (giving more importance to the last game's performance rather than to the second to last etc.).\n",
    "    2) It seems like we do not have enough data considering its dimension (1230 instances for 32 attributes). An error we made above was to only consider data from the 2017-2018 season on the grounds that games from previous seasons did not influence the results from the present season. What that means is that while preprocessing the data, instances from one season shoud stay independent from the ones of a different season. But nothing prevents us from using data from previous seasons in order to train our model.\n",
    "    3) If adding the data from previous seasons isn't satisfying enough, we'll consider applying dimensional reduction methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Re-preprocessing the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In order to make our data preprocessing easier, we will restructure the raw data.\n",
    "We will create a 4D array. The first dimension corresponds to the season the game was played in, the second dimension corresponds to the team of the data, the third dimension corresponds to the data itself and the fourth dimension corresponds to the attributes of the data.\n",
    "This structure was chosen in consequence to the remarks made at the end of Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Load data from .csv file\n",
    "\n",
    "with open('nba.games.stats.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=',', quotechar = '\"')\n",
    "    \n",
    "    # Initialize list of raw data from 2017-2018 season\n",
    "    raw_data = []\n",
    "    raw_data_test = []\n",
    "    for row in reader:\n",
    "        if not row[3]=='Date':\n",
    "            raw_data.append(row[1:])\n",
    "            raw_data_test.append(row[1:])\n",
    "\n",
    "                \n",
    "# Transform the statistics from strings to floats\n",
    "for i in range(len(raw_data)):\n",
    "    raw_data[i][1] = float(raw_data[i][1])\n",
    "    for j in range(6,40):\n",
    "        raw_data[i][j] = float(raw_data[i][j])\n",
    "        \n",
    "# teams is the list of teams in alphabetical order\n",
    "teams = []\n",
    "for data in raw_data:\n",
    "    if data[0] not in teams:\n",
    "        teams.append(data[0])\n",
    "\n",
    "#  Change the name of the team to its index in teams\n",
    "# 'Away' takes value 0 and 'Home' takes value +1\n",
    "# Change the opponent's name to its index in teams\n",
    "# W takes value +1 and L takes value 0\n",
    "for data in raw_data:\n",
    "    data[0] = float(teams.index(data[0]))\n",
    "    if data[3] == 'Home': data[3] = 1.\n",
    "    else: data[3] = 0.\n",
    "    data[4] = float(teams.index(data[4]))\n",
    "    if data[5] == 'W': data[5] = 1.\n",
    "    else: data[5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Data Preprocessing\n",
    "\n",
    "# Storing the data by season\n",
    "raw_data_season = [[w for w in raw_data if date_to_tuple(w[2])<(2015,6,17)], [w for w in raw_data if (2015,6,20)<date_to_tuple(w[2]) and date_to_tuple(w[2])<(2016,6,20)], [w for w in raw_data if (2016,6,20)<date_to_tuple(w[2]) and date_to_tuple(w[2])<(2017,6,20)], [w for w in raw_data if (2017,6,20)<date_to_tuple(w[2])]]\n",
    "\n",
    "# restructured_raw_data will contain our raw_data restructured as explained in the text above\n",
    "restructured_raw_data = []\n",
    "\n",
    "# Storing the data by teams\n",
    "for season in raw_data_season:\n",
    "    # season_divided_teams is a 2D list containing data of the season divided by teams\n",
    "    season_divided_teams = []\n",
    "    for i in range(30):\n",
    "        # data_set_team contains all data from the team i and from the season season\n",
    "        data_set_team = []\n",
    "        for data in season:\n",
    "            if data[0] == i:\n",
    "                data_set_team.append(data)\n",
    "        season_divided_teams.append(data_set_team)\n",
    "    restructured_raw_data.append(season_divided_teams)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    At this point, we need to make our data predictable (cf. explanation in part A). \n",
    "    We noticed that in our computation of the statistical attributes, we weren't taking into account a team's dynamic. Indeed, during a season, they will have highs and lows during which they will be more keen to perform well or not.\n",
    "    We will represent this dynamic by computing the statistical attributes as a weighted mean of the past few games. Deciding for the ponderation of the mean is a difficulty in itself. Ideally, the games played in the past two weeks or so should have much more influence than the ones played before that.\n",
    "    So let n(i,j) be the number of days elapsed between game i and game j for which we would like to compute the statistical attributes. We decided that the weight of game i's statistics in the computation of j's statistics will be of the form: w(i,j)=1/n(i,j)^alpha where alpha is a positive parameter we will try to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a function that gives the number of days between date1 and date2\n",
    "# date2 > date1\n",
    "from datetime import date\n",
    "def lapse(date1, date2):\n",
    "    date1 = date(date_to_tuple(date1)[0], date_to_tuple(date1)[1], date_to_tuple(date1)[2])\n",
    "    date2 = date(date_to_tuple(date2)[0], date_to_tuple(date2)[1], date_to_tuple(date2)[2])\n",
    "    delta = date2 - date1\n",
    "    return(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the weight between a match on day i and a match on day j\n",
    "def weight(date1, date2, alpha):\n",
    "        return(1/(lapse(date1,date2)**alpha))\n",
    "    \n",
    "# Implementing the weighted mean over a set of raw_data: interesting_data\n",
    "# Returns an array of the statistical attributes in the following order : teamPoints, opponentPoints, fieldGoals, fieldGoalsPour, threePoints, threePointsPour, freeThrows, freeThrowsPour, offRebounds, totRebounds, assists, steals, blocks, turnovers, totalFouls\n",
    "def weighted_mean(i,j,k,interesting_data, alpha):\n",
    "    i,j,k = int(i),int(j),int(k)\n",
    "    if len(interesting_data)==0:\n",
    "        return np.zeros(15)\n",
    "    else:\n",
    "        interesting_date = restructured_raw_data[i][j][k][2]\n",
    "        total_weight = 0\n",
    "        weighted_sum = np.zeros(15)\n",
    "        for data in interesting_data:\n",
    "            data_weight = weight(data[2], interesting_date, alpha)\n",
    "            weighted_sum = weighted_sum + data_weight*np.array(data[6:21])\n",
    "            total_weight += data_weight\n",
    "        return(weighted_sum/total_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the set of data corresponding to matchs that will be taken into account in order to compute the statistical attributes\n",
    "# i,j,k are the coordinates of our instance\n",
    "def find_interesting_data(i,j,k,HomeOrAway):\n",
    "    interesting_data = []\n",
    "    i,j,k = int(i),int(j),int(k)\n",
    "    # Among the data from the i-th season and team j, we only consider matchs played before the data's date\n",
    "    for data in restructured_raw_data[i][j]:\n",
    "        if data[3] == HomeOrAway and date_to_tuple(data[2]) < date_to_tuple(restructured_raw_data[i][j][k][2]):\n",
    "            interesting_data.append(data)\n",
    "    return interesting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coordinates of the data corresponding to the away team\n",
    "def find_away_data_2(i,j,k):\n",
    "    opponentID = restructured_raw_data[i][j][k][4]\n",
    "    potential_data = restructured_raw_data[i][int(opponentID)]\n",
    "    for p in range(len(potential_data)):\n",
    "        # If the date of both instances is the same, it describes the same match\n",
    "        if restructured_raw_data[i][int(opponentID)][p][2] == restructured_raw_data[i][j][k][2]:\n",
    "            return (i,int(opponentID),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the preprocessed data and the labels\n",
    "\n",
    "preprocessed_data = []\n",
    "labels = []\n",
    "alpha = 1\n",
    "\n",
    "for i in range(len(restructured_raw_data)):\n",
    "    for j in range(len(restructured_raw_data[0])):\n",
    "        for k in range(len(restructured_raw_data[0][0])):\n",
    "            if restructured_raw_data[i][j][k][3] == 1:\n",
    "                opponent_data_coordinates = find_away_data_2(i,j,k)\n",
    "                home_interesting_data = find_interesting_data(i,j,k,1)\n",
    "                # l,m,n are the away coordinates\n",
    "                (l,m,n) = find_away_data_2(i,j,k)\n",
    "                away_interesting_data = find_interesting_data(l, m, n, 0)\n",
    "                home_stats = weighted_mean(i,j,k,home_interesting_data, alpha)\n",
    "                away_stats = weighted_mean(i,j,k,away_interesting_data, alpha)\n",
    "                #filling labels\n",
    "                if restructured_raw_data[i][j][k][5] == 1.: labels.append(1)\n",
    "                else: labels.append(0)\n",
    "                # Computing the final data\n",
    "                data = np.zeros(len(home_stats)+len(away_stats)+4)\n",
    "                homeID = restructured_raw_data[i][j][k][0]\n",
    "                awayID = restructured_raw_data[l][m][n][0]\n",
    "                homeGameNumber = restructured_raw_data[i][j][k][1]\n",
    "                awayGameNumber = restructured_raw_data[l][m][n][1]\n",
    "                data[0] = homeID\n",
    "                data[1] = awayID\n",
    "                data[2] = homeGameNumber\n",
    "                counter = 3\n",
    "                for stat in range(len(home_stats)):\n",
    "                    data[counter] = home_stats[stat]\n",
    "                    counter +=1\n",
    "                data[counter] = awayGameNumber\n",
    "                counter +=1\n",
    "                for stat in range(len(away_stats)):\n",
    "                    data[counter] = away_stats[stat]\n",
    "                    counter += 1\n",
    "                preprocessed_data.append(data)\n",
    "                \n",
    "preprocessed_data = np.array(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D) Back to applying classical algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d7de7023b612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.33, random_state=42)\n",
    "regressor = DecisionTreeRegressor(random_state =1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6009852216748769\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 9, 'n_estimators': 194}\n",
      "Score:  0.6286407766990292\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [2*n for n in range(75, 100)],\n",
    "    'max_depth':[3,5,7,9,10]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", gridSearch.best_params_)\n",
    "print(\"Score: \", gridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5800492610837439\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "# Using the MLP classifier that trains the model by backpropagation\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.582\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.595\n",
      "Accuracy score (validation): 0.591\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.610\n",
      "Accuracy score (validation): 0.596\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.650\n",
      "Accuracy score (validation): 0.603\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.666\n",
      "Accuracy score (validation): 0.610\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.668\n",
      "Accuracy score (validation): 0.615\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.674\n",
      "Accuracy score (validation): 0.610\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6625615763546798\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Results are much poorer than in the previous case. To that, we could not find much explanation a part for the fact that our interpretation of the data probably isn't the appropriate one. So we will abandon the weighted mean.\n",
    "I believe that whilst taking into account all 4 seasons is a good idea, keeping the teamIDs as an attribute isn't adapted anymore. Indeed, teams' performances fluctuate a lot between seasons, so the fact that team1 won a lot of games on season 2014-2015 should not have any influence on its performances of season 2017-2018.\n",
    "We'll try stripping these attributes from our data.\n",
    "If results are still unsatisfying, we'll consider Dimensionnality Reduction algorithms. It could be useful as some attributes in our data may be redundant with one another (e.g: 3point attributes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E) Third data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Load data from .csv file\n",
    "\n",
    "with open('nba.games.stats.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=',', quotechar = '\"')\n",
    "    \n",
    "    # Initialize list of raw data from 2017-2018 season\n",
    "    raw_data = []\n",
    "    raw_data_test = []\n",
    "    for row in reader:\n",
    "        if not row[3]=='Date':\n",
    "            raw_data.append(row[1:])\n",
    "            raw_data_test.append(row[1:])\n",
    "\n",
    "                \n",
    "# Transform the statistics from strings to floats\n",
    "for i in range(len(raw_data)):\n",
    "    raw_data[i][1] = float(raw_data[i][1])\n",
    "    for j in range(6,40):\n",
    "        raw_data[i][j] = float(raw_data[i][j])\n",
    "        \n",
    "# teams is the list of teams in alphabetical order\n",
    "teams = []\n",
    "for data in raw_data:\n",
    "    if data[0] not in teams:\n",
    "        teams.append(data[0])\n",
    "\n",
    "#  Change the name of the team to its index in teams\n",
    "# 'Away' takes value 0 and 'Home' takes value +1\n",
    "# Change the opponent's name to its index in teams\n",
    "# W takes value +1 and L takes value 0\n",
    "for data in raw_data:\n",
    "    data[0] = float(teams.index(data[0]))\n",
    "    if data[3] == 'Home': data[3] = 1.\n",
    "    else: data[3] = 0.\n",
    "    data[4] = float(teams.index(data[4]))\n",
    "    if data[5] == 'W': data[5] = 1.\n",
    "    else: data[5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Data Preprocessing\n",
    "\n",
    "# Storing the data by season\n",
    "raw_data_season = [[w for w in raw_data if date_to_tuple(w[2])<(2015,6,17)], [w for w in raw_data if (2015,6,20)<date_to_tuple(w[2]) and date_to_tuple(w[2])<(2016,6,20)], [w for w in raw_data if (2016,6,20)<date_to_tuple(w[2]) and date_to_tuple(w[2])<(2017,6,20)], [w for w in raw_data if (2017,6,20)<date_to_tuple(w[2])]]\n",
    "\n",
    "# restructured_raw_data will contain our raw_data restructured as explained in the text above\n",
    "restructured_raw_data = []\n",
    "\n",
    "# Storing the data by teams\n",
    "for season in raw_data_season:\n",
    "    # season_divided_teams is a 2D list containing data of the season divided by teams\n",
    "    season_divided_teams = []\n",
    "    for i in range(30):\n",
    "        # data_set_team contains all data from the team i and from the season season\n",
    "        data_set_team = []\n",
    "        for data in season:\n",
    "            if data[0] == i:\n",
    "                data_set_team.append(data)\n",
    "        season_divided_teams.append(data_set_team)\n",
    "    restructured_raw_data.append(season_divided_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the set of data corresponding to matchs that will be taken into account in order to compute the statistical attributes\n",
    "# i,j,k are the coordinates of our instance\n",
    "def find_interesting_data2(i,j,k,HomeOrAway):\n",
    "    interesting_data = []\n",
    "    i,j,k = int(i),int(j),int(k)\n",
    "    # Among the data from the i-th season and team j, we only consider matchs played before the data's date\n",
    "    for data in restructured_raw_data[i][j]:\n",
    "        if data[3] == HomeOrAway and date_to_tuple(data[2]) < date_to_tuple(restructured_raw_data[i][j][k][2]):\n",
    "            interesting_data.append(data[7:])\n",
    "    return np.array(interesting_data)\n",
    "\n",
    "# Computing a function season_stats adapted to the structure of our data \n",
    "# Returns the arithmetic mean of each stat during the season\n",
    "\n",
    "def season_stats(interesting_data):\n",
    "    interesting_data = np.array(interesting_data)\n",
    "    if interesting_data.shape[0] > 0:\n",
    "    #Returns in that order: teamPoints, opponentPoints, fieldGoals, fieldGoalsPour, threePoints, threePointsPour, freeThrows, freeThrowsPour, offRebounds, totRebounds, assists, steals, blocks, turnovers, totalFouls\n",
    "        return(np.mean(interesting_data[:,[0,2,4,5,6,7,8,10,11,12,13,14,15,16,17]], axis=0))\n",
    "    return(np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the preprocessed data and the labels\n",
    "\n",
    "preprocessed_data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(restructured_raw_data)):\n",
    "    for j in range(len(restructured_raw_data[0])):\n",
    "        for k in range(len(restructured_raw_data[0][0])):\n",
    "            if restructured_raw_data[i][j][k][3] == 1:\n",
    "                home_interesting_data = find_interesting_data2(i,j,k,1)\n",
    "                # l,m,n are the away coordinates\n",
    "                l,m,n = find_away_data_2(i,j,k)\n",
    "                away_interesting_data = find_interesting_data2(l, m, n, 0)\n",
    "                # taking the arithmetic mean\n",
    "                home_stats = season_stats(home_interesting_data)\n",
    "                away_stats = season_stats(away_interesting_data)\n",
    "                # filling labels\n",
    "                if restructured_raw_data[i][j][k][5] == 1.: labels.append(1)\n",
    "                else: labels.append(0)\n",
    "                # Computing the final data\n",
    "                data = np.zeros(len(home_stats)+len(away_stats)+4)\n",
    "                homeID = restructured_raw_data[i][j][k][0]\n",
    "                awayID = restructured_raw_data[l][m][n][0]\n",
    "                homeGameNumber = restructured_raw_data[i][j][k][1]\n",
    "                awayGameNumber = restructured_raw_data[l][m][n][1]\n",
    "                data[0] = homeGameNumber\n",
    "                counter = 1\n",
    "                for stat in range(len(home_stats)):\n",
    "                    data[counter] = home_stats[stat]\n",
    "                    counter +=1\n",
    "                data[counter] = awayGameNumber\n",
    "                counter +=1\n",
    "                for stat in range(len(away_stats)):\n",
    "                    data[counter] = away_stats[stat]\n",
    "                    counter += 1\n",
    "                preprocessed_data.append(data)\n",
    "                \n",
    "preprocessed_data = np.array(preprocessed_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F) Third application of classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.33, random_state=42)\n",
    "regressor = DecisionTreeRegressor(random_state =1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test).round()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Decision trees give a very unsatisfying result. Let's try the bagging version of decision trees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604064039408867\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 10, 'n_estimators': 156}\n",
      "Score:  0.6386529126213593\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [2*n for n in range(75, 100)],\n",
    "    'max_depth':[3,5,7,9,10]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", gridSearch.best_params_)\n",
    "print(\"Score: \", gridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5800492610837439\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "# Using the MLP classifier that trains the model by backpropagation\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.583\n",
      "Accuracy score (validation): 0.579\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.589\n",
      "Accuracy score (validation): 0.585\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.603\n",
      "Accuracy score (validation): 0.591\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.655\n",
      "Accuracy score (validation): 0.618\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.679\n",
      "Accuracy score (validation): 0.632\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.682\n",
      "Accuracy score (validation): 0.626\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.683\n",
      "Accuracy score (validation): 0.621\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6231527093596059\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "At the end of the day, it was our first data structure that gave the best results. May we see any improvement coming from dimension reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G) Dimension Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Load data from .csv file\n",
    "\n",
    "with open('nba.games.stats.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=',', quotechar = '\"')\n",
    "    \n",
    "    # Initialize list of raw data from 2017-2018 season\n",
    "    raw_data = []\n",
    "    raw_data_test = []\n",
    "    for row in reader:\n",
    "        if not row[3]=='Date':\n",
    "            if (2017,10,1) < date_to_tuple(row[3]):\n",
    "                raw_data.append(row[1:])\n",
    "                raw_data_test.append(row[1:])\n",
    "\n",
    "                \n",
    "# Transform the statistics from strings to floats\n",
    "for i in range(len(raw_data)):\n",
    "    raw_data[i][1] = float(raw_data[i][1])\n",
    "    for j in range(6,40):\n",
    "        raw_data[i][j] = float(raw_data[i][j])\n",
    "        \n",
    "# teams is the list of teams in alphabetical order\n",
    "teams = []\n",
    "for data in raw_data:\n",
    "    if data[0] not in teams:\n",
    "        teams.append(data[0])\n",
    "\n",
    "#  Change the name of the team to its index in teams\n",
    "# 'Away' takes value 0 and 'Home' takes value +1\n",
    "# Change the opponent's name to its index in teams\n",
    "# W takes value +1 and L takes value 0\n",
    "for data in raw_data:\n",
    "    data[0] = float(teams.index(data[0]))\n",
    "    if data[3] == 'Home': data[3] = 1.\n",
    "    else: data[3] = 0.\n",
    "    data[4] = float(teams.index(data[4]))\n",
    "    if data[5] == 'W': data[5] = 1.\n",
    "    else: data[5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Data Preprocessing\n",
    "\n",
    "# Finds the data correponding to the away team\n",
    "def find_away_data(data):\n",
    "    for away_data in raw_data:\n",
    "        # If the matches were held on the same day and the teams are the same, then it is the same match\n",
    "        if away_data[2] == data[2] and away_data[4] == data[0]:\n",
    "            return away_data\n",
    "\n",
    "# Computes the statistical attributes of a team with regard to the date and the home/away status of the game\n",
    "# At this point, we are only computing the isomean of the stats on every past game (no weighted mean)\n",
    "def stats(teamID, date, HomeOrAway):\n",
    "    # Take all of the games previously played by the team at HomeOrAway before the date \n",
    "    interesting_data = np.array([w[7:] for w in raw_data if teamID == w[0] and HomeOrAway == w[3] and w[2] < date ])\n",
    "    if interesting_data.shape[0] > 0:\n",
    "    #Returns in that order: teamPoints, opponentPoints, fieldGoals, fieldGoalsPour, threePoints, threePointsPour, freeThrows, freeThrowsPour, offRebounds, totRebounds, assists, steals, blocks, turnovers, totalFouls\n",
    "        return(np.mean(interesting_data[:,[0,2,4,5,6,7,8,10,11,12,13,14,15,16,17]], axis=0))\n",
    "    return(np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data=[]\n",
    "labels = []\n",
    "\n",
    "# For the labels, +1 indicates a home win, 0 indicates an away win\n",
    "\n",
    "for data in raw_data:\n",
    "    if data[3] == 1.:\n",
    "        # Computing every attribute necessary for the data\n",
    "        away_data = find_away_data(data)\n",
    "        home_teamID = data[0]\n",
    "        away_teamID = away_data[0]\n",
    "        date = data[2]\n",
    "        homeGameNumber = data[1]\n",
    "        awayGameNumber = away_data[1]\n",
    "        home_stats = stats(home_teamID, date, 1.)\n",
    "        away_stats = stats(away_teamID, date, 0.)\n",
    "        #filling labels\n",
    "        if data[5] == 1.: labels.append(1)\n",
    "        else: labels.append(0)\n",
    "        data = np.zeros(len(home_stats)+len(away_stats)+4)\n",
    "        # Creating the new data instance\n",
    "        data[0] = home_teamID\n",
    "        data[1] = away_teamID\n",
    "        data[2] = homeGameNumber\n",
    "        counter = 3\n",
    "        for i in range(len(home_stats)):\n",
    "            data[counter] = home_stats[i]\n",
    "            counter += 1\n",
    "        data[counter] = awayGameNumber\n",
    "        counter += 1\n",
    "        for i in range(len(away_stats)):\n",
    "            data[counter] = away_stats[i]\n",
    "            counter += 1\n",
    "        preprocessed_data.append(data)\n",
    "        \n",
    "# Our data matrix is of size 1230 x 34; see preprocessing text for further understanding\n",
    "preprocessed_data = np.array(preprocessed_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732590064853615\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Choosing the right dimension of the data\n",
    "# Keeping around 99% of the data's energy using SVD\n",
    "\n",
    "u, sigma, vh = np.linalg.svd(preprocessed_data, full_matrices=True)\n",
    "variance_matrix = sigma**2\n",
    "total_variance = np.sum(variance_matrix)\n",
    "\n",
    "print(variance_matrix[0]/total_variance)\n",
    "\n",
    "i=0\n",
    "info = variance_matrix[0]\n",
    "while info < 0.99*total_variance:\n",
    "    i += 1\n",
    "    info += variance_matrix[i]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "[[108.03535758  43.27049886]\n",
      " [ 36.64786521 -33.59230572]\n",
      " [ 28.31096681 -35.78493625]\n",
      " ...\n",
      " [-41.45139661  28.26191441]\n",
      " [-44.90437521  31.93424576]\n",
      " [-41.91665267  37.1327939 ]]\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "print (len(preprocessed_data[0]))\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_data = pca.fit_transform(preprocessed_data)\n",
    "print(reduced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H) Applying classification to the reduced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5960591133004927"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.33, random_state=42)\n",
    "regressor = DecisionTreeRegressor(random_state =1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 5, 'n_estimators': 174}\n",
      "Score:  0.6468446601941747\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [2*n for n in range(75, 100)],\n",
    "    'max_depth':[3,5,7,9,10]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", gridSearch.best_params_)\n",
    "print(\"Score: \", gridSearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5886699507389163\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "# Using the MLP classifier that trains the model by backpropagation\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.604\n",
      "Accuracy score (validation): 0.594\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.623\n",
      "Accuracy score (validation): 0.623\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.654\n",
      "Accuracy score (validation): 0.603\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.699\n",
      "Accuracy score (validation): 0.611\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.757\n",
      "Accuracy score (validation): 0.628\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.762\n",
      "Accuracy score (validation): 0.616\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.762\n",
      "Accuracy score (validation): 0.601\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6354679802955665\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
